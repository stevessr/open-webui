"""
title: Gemini with search & code (Pseudo-streaming) - Robust Version with Detailed Token Calculation
licence: MIT
"""

import json
import logging
import time
import uuid
import re
import base64
from typing import AsyncIterable, Optional, Callable, Awaitable, AsyncGenerator, List
import asyncio

import httpx
from pydantic import BaseModel, Field

# å‡è®¾ open_webui.env å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨æ ‡å‡†çš„ logging é…ç½®
try:
    from open_webui.env import SRC_LOG_LEVELS

    log_level = SRC_LOG_LEVELS["MAIN"]
except ImportError:
    log_level = logging.INFO

# é…ç½®æ—¥å¿—è®°å½•å™¨
logging.basicConfig(
    level=log_level, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)
logger.setLevel(log_level)


class Pipe:
    """
    ä¸€ä¸ªç”¨äºä¸ Gemini API äº¤äº’çš„ Manifold é£æ ¼ç®¡é“ã€‚
    è¯¥ç®¡é“å¤„ç†æµå¼å“åº”å¹¶æä¾›çŠ¶æ€æ›´æ–°ï¼Œæ”¯æŒç‹¬ç«‹çš„æ–‡ä»¶ä¸Šä¼ é…ç½®ï¼ˆURL å’Œ API Keyï¼‰ã€‚
    """

    class Valves(BaseModel):
        # --- åŸºç¡€ API é…ç½® (ç”¨äºå¯¹è¯ç”Ÿæˆ) ---
        base_url: str = Field(
            default="https://generativelanguage.googleapis.com",
            description="Gemini ç”Ÿæˆ API çš„åŸºç¡€ URL (ç”¨äº chat/generateContent)ã€‚",
        )
        api_key: str = Field(default="", description="ç”¨äºå¯¹è¯ç”Ÿæˆçš„ Gemini API å¯†é’¥ã€‚")

        # --- æ–‡ä»¶ä¸Šä¼  API é…ç½® (ç‹¬ç«‹) ---
        file_api_base_url: str = Field(
            default="https://generativelanguage.googleapis.com",
            description="Gemini æ–‡ä»¶ä¸Šä¼  API çš„åŸºç¡€ URL (ç”¨äº upload/files)ã€‚",
        )
        file_api_key: str = Field(
            default="",
            description="ç”¨äºæ–‡ä»¶ä¸Šä¼ çš„ Gemini API å¯†é’¥ã€‚å¦‚æœç•™ç©ºï¼Œå°†é»˜è®¤ä½¿ç”¨ä¸Šé¢çš„ api_keyã€‚",
        )

        timeout: int = Field(default=600, description="æ•´ä¸ªè¯·æ±‚çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰")

        # --- æµå¼å’Œè¶…æ—¶é…ç½® ---
        stream_idle_timeout: int = Field(
            default=30, description="åœ¨å‡å®šè¿æ¥ä¸­æ–­ä¹‹å‰ï¼Œç­‰å¾…æ–°æ•°æ®çš„æœ€é•¿æ—¶é—´ï¼ˆç§’ï¼‰ã€‚"
        )

        # --- æ¨¡å‹é…ç½® ---
        model_id: str = Field(
            default="gemini-2.5-flash-lite",
            description="UI ä¸­ä½¿ç”¨çš„æ¨¡å‹ IDã€‚",
        )
        model_display_name: str = Field(
            default="Gemini 2.5 Flash Lite ç ”ç©¶", description="UI ä¸­æ˜¾ç¤ºçš„æ¨¡å‹åç§°ã€‚"
        )
        api_model: str = Field(
            default="gemini-2.5-flash-lite",
            description="ç”¨äº API è°ƒç”¨çš„å®é™… Gemini æ¨¡å‹åç§°ã€‚",
        )

    class UserValves(BaseModel):
        # æ€è€ƒé¢„ç®—é…ç½®
        thinking_budget: int = Field(
            default=-1,
            description="Gemini API çš„æ€è€ƒé¢„ç®—ï¼ˆthinkingBudgetï¼‰ã€‚è®¾ç½®ä¸º 0 å…³é—­æ€è€ƒï¼Œ-1 å¼€å¯åŠ¨æ€æ€è€ƒã€‚",
        )
        include_thoughts: bool = Field(
            default=True, description="æ˜¯å¦è¿”å› Gemini çš„æ€è€ƒæ‘˜è¦"
        )
        # è¾“å‡ºå»¶è¿Ÿé…ç½®
        output_delay: float = Field(
            default=0.01,
            description="è¾“å‡ºå»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰ã€‚åœ¨å­—ç¬¦æ¨¡å¼ä¸‹ä¸ºæ¯ä¸ªå­—ç¬¦é—´çš„å»¶è¿Ÿï¼Œåœ¨å—æ¨¡å¼ä¸‹ä¸ºæ¯ä¸ªå—é—´çš„å»¶è¿Ÿã€‚è®¾ç½®ä¸º 0 ä»¥ç¦ç”¨ã€‚",
        )
        # å—çŠ¶è¾“å‡ºé…ç½®
        block_size: int = Field(
            default=10,
            description="æ¯ä¸ªè¾“å‡ºå—çš„å­—ç¬¦æ•°ã€‚å½“å¤§äº 1 æ—¶åˆ†å—è¾“å‡ºï¼Œä¸º 1 æ—¶é€å­—ç¬¦è¾“å‡ºï¼Œå°äº 0 æ—¶æŒ‰ç©ºæ ¼åˆ†å—è¾“å‡ºã€‚",
        )
        # temperature å’Œ top_P é…ç½®
        temperature: float = Field(default=0.7, description="æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ã€‚")
        top_p: float = Field(default=0.9, description="æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§ã€‚")

    def __init__(self):
        self.type = "manifold"
        self.name = ""
        self.valves = self.Valves()
        self.uservalues = self.UserValves()
        self.emitter: Optional[Callable[[dict], Awaitable[None]]] = None
        logger.info(f"ç®¡é“ '{self.name}' å·²åˆå§‹åŒ–ã€‚")

    async def emit_status(self, message: str, done: bool = False):
        if self.emitter:
            status_payload = {
                "type": "status",
                "data": {"description": str(message)[:500], "done": done},
            }
            logger.debug(f"å‘é€çŠ¶æ€æ›´æ–°ï¼š{status_payload}")
            await self.emitter(status_payload)

    def get_models(self) -> List[dict]:
        return [
            {
                "id": self.valves.model_id,
                "name": self.valves.model_display_name,
            },
        ]

    def pipes(self) -> List[dict]:
        return self.get_models()

    def split_html_tags(self, text: str) -> List[str]:
        """
        å°†æ–‡æœ¬åˆ†å‰²ä¸º HTML æ ‡ç­¾å’Œæ™®é€šæ–‡æœ¬å—çš„åˆ—è¡¨
        """
        pattern = r"(<[^>]+>)"
        return re.split(pattern, text)

    async def _upload_file(
        self, client: httpx.AsyncClient, mime_type: str, data: bytes
    ) -> str:
        """
        ä½¿ç”¨ Gemini File API çš„å¯æ¢å¤ä¸Šä¼ åè®®ä¸Šä¼ æ–‡ä»¶å­—èŠ‚ã€‚
        ä½¿ç”¨ self.valves.file_api_base_url å’Œ self.valves.file_api_keyã€‚
        """
        num_bytes = len(data)
        display_name = "Uploaded Image"

        # 1. ç¡®å®šä½¿ç”¨çš„ API Key (ä¼˜å…ˆä½¿ç”¨ç‹¬ç«‹çš„ä¸Šä¼  Keyï¼Œæ²¡æœ‰åˆ™å›é€€åˆ°ä¸» Key)
        upload_api_key = (
            self.valves.file_api_key
            if self.valves.file_api_key
            else self.valves.api_key
        )

        if not upload_api_key:
            raise ValueError("æœªè®¾ç½®ä¸Šä¼ ç”¨çš„ API Key (file_api_key æˆ– api_key å‡ä¸ºç©º)")

        # 2. æ„é€ ä¸Šä¼ åˆå§‹ URL
        base_upload_url = self.valves.file_api_base_url.rstrip("/")
        if not base_upload_url:
            base_upload_url = "https://generativelanguage.googleapis.com"

        # ç®€å•çš„è·¯å¾„æ‹¼æ¥ï¼Œç¡®ä¿æŒ‡å‘ /upload/v1beta/files
        if base_upload_url.endswith("/upload/v1beta/files"):
            upload_endpoint = base_upload_url
        else:
            upload_endpoint = f"{base_upload_url}/upload/v1beta/files"

        params = {"key": upload_api_key}

        headers_init = {
            "X-Goog-Upload-Protocol": "resumable",
            "X-Goog-Upload-Command": "start",
            "X-Goog-Upload-Header-Content-Length": str(num_bytes),
            "X-Goog-Upload-Header-Content-Type": mime_type,
            "Content-Type": "application/json",
        }

        payload_init = {"file": {"display_name": display_name}}

        logger.info(
            f"å¼€å§‹ä¸Šä¼ æ–‡ä»¶ ({num_bytes} bytes, {mime_type}) åˆ°ï¼š{upload_endpoint}"
        )

        try:
            resp_init = await client.post(
                upload_endpoint, params=params, headers=headers_init, json=payload_init
            )
            resp_init.raise_for_status()
        except httpx.HTTPStatusError as e:
            logger.error(f"ä¸Šä¼ åˆå§‹åŒ–å¤±è´¥ï¼š{e.response.text}")
            raise e

        # ä»å“åº”å¤´è·å–å®é™…çš„ä¸Šä¼  URL
        upload_url = resp_init.headers.get("x-goog-upload-url")
        if not upload_url:
            raise ValueError("æœªä» API æ”¶åˆ° x-goog-upload-url")

        # 3. ä¸Šä¼ å®é™…å­—èŠ‚
        headers_upload = {
            "Content-Length": str(num_bytes),
            "X-Goog-Upload-Offset": "0",
            "X-Goog-Upload-Command": "upload, finalize",
        }

        # æ³¨æ„ï¼šupload_url é€šå¸¸æ˜¯ä¸€ä¸ªå®Œæ•´çš„ç»å¯¹è·¯å¾„ï¼Œhttpx ä¼šç›´æ¥ä½¿ç”¨å®ƒ
        resp_upload = await client.post(
            upload_url, headers=headers_upload, content=data
        )
        resp_upload.raise_for_status()

        file_info = resp_upload.json()
        file_uri = file_info.get("file", {}).get("uri")

        if not file_uri:
            raise ValueError("ä¸Šä¼ å®Œæˆä½†æœªæ”¶åˆ° file_uri")

        logger.info(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼š{file_uri}")
        return file_uri

    async def process_stream(
        self, response: httpx.Response
    ) -> AsyncGenerator[str, None]:
        """å¤„ç†æ¥è‡ª Gemini API çš„æœåŠ¡å™¨å‘é€äº‹ä»¶ (SSE) æµã€‚"""
        logger.info("å¼€å§‹å¤„ç† API å“åº”æµã€‚")
        finish_reason_received = False
        stream_iterator = response.aiter_lines()
        content_yielded = False
        is_thinking = False

        try:
            while True:
                try:
                    line = await asyncio.wait_for(
                        stream_iterator.__anext__(),
                        timeout=self.valves.stream_idle_timeout,
                    )

                    if not line.strip() or not line.startswith("data: "):
                        continue

                    line = line[6:]

                    try:
                        chunk = json.loads(line)

                        if "error" in chunk:
                            error_detail = chunk.get("error", {}).get(
                                "message", "æµä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯"
                            )
                            error_msg = f"ğŸš¨ Gemini API é”™è¯¯ï¼š{error_detail}"
                            logger.error(error_msg)
                            await self.emit_status(error_msg, done=True)
                            yield error_msg
                            return

                        if "candidates" in chunk:
                            for candidate in chunk.get("candidates", []):
                                if (
                                    "content" in candidate
                                    and "parts" in candidate["content"]
                                ):
                                    for part in candidate["content"]["parts"]:
                                        is_thought_part = part.get("thought") is True
                                        text_content = part.get("text", "")

                                        if not text_content:
                                            continue

                                        content_yielded = True

                                        if is_thought_part:
                                            prefix = ""
                                            if not is_thinking:
                                                prefix = "<think>"
                                                is_thinking = True

                                            quoted_lines = [
                                                f"> {line}"
                                                for line in text_content.splitlines()
                                            ]
                                            quoted_thought = "\n".join(quoted_lines)

                                            if text_content.endswith("\n"):
                                                quoted_thought += "\n"

                                            if (
                                                not quoted_thought
                                                and text_content.strip() == ""
                                            ):
                                                quoted_thought = text_content

                                            yield prefix + quoted_thought

                                        else:
                                            prefix = ""
                                            if is_thinking:
                                                prefix = "</think>"
                                                is_thinking = False

                                            yield prefix + text_content

                        if usage_metadata := chunk.get("usageMetadata"):
                            usage_parts = []
                            prompt_tokens = usage_metadata.get("promptTokenCount", 0)
                            candidates_tokens = usage_metadata.get(
                                "candidatesTokenCount", 0
                            )
                            total_tokens = usage_metadata.get("totalTokenCount", 0)

                            thoughts_tokens = usage_metadata.get(
                                "thoughtsTokenCount", 0
                            )
                            tool_use_tokens = usage_metadata.get("toolUseTokenCount", 0)
                            grounding_tokens = usage_metadata.get(
                                "groundingTokenCount", 0
                            )

                            thinking_and_tool_tokens = (
                                thoughts_tokens + tool_use_tokens + grounding_tokens
                            )

                            output_text_tokens = (
                                candidates_tokens - thinking_and_tool_tokens
                            )

                            usage_parts.append(f"è¾“å…¥ï¼š{prompt_tokens}")

                            if output_text_tokens > 0:
                                usage_parts.append(f"è¾“å‡º (å†…å®¹): {output_text_tokens}")

                            if thinking_and_tool_tokens > 0:
                                usage_parts.append(
                                    f"è¾“å‡º (æ€è€ƒ/å·¥å…·): {thinking_and_tool_tokens}"
                                )

                            usage_parts.append(f"æ€»è®¡ï¼š{total_tokens}")

                            usage_msg = (
                                f"Token ç”¨é‡ï¼š{', '.join(usage_parts)}"
                                if usage_parts
                                else "ç”¨é‡ä¿¡æ¯å¯ç”¨"
                            )
                            logger.debug(usage_msg)
                            await self.emit_status(usage_msg, done=False)

                        if finish_reason := chunk.get("candidates", [{}])[0].get(
                            "finishReason"
                        ):
                            logger.info(f"ä» API æ”¶åˆ°å®ŒæˆåŸå› ï¼š{finish_reason}")
                            finish_reason_received = True

                    except json.JSONDecodeError:
                        logger.warning(f"è§£ç  JSON è¡Œå¤±è´¥ï¼š{line}. è·³è¿‡æ­¤è¡Œã€‚")
                    except Exception as e:
                        logger.debug(f"å¤„ç†æ•°æ®å—é”™è¯¯ï¼š{e}. è·³è¿‡æ­¤å—ã€‚")

                except StopAsyncIteration:
                    logger.info("å“åº”æµæ­£å¸¸ç»“æŸã€‚")
                    break
                except asyncio.TimeoutError:
                    error_msg = f"ğŸš¨ æµè¶…æ—¶ï¼šåœ¨ {self.valves.stream_idle_timeout} ç§’å†…æœªæ”¶åˆ°æ–°æ•°æ®ã€‚"
                    logger.error(error_msg)
                    await self.emit_status(error_msg, done=True)
                    yield error_msg
                    return

            if is_thinking:
                yield "</think>"
                is_thinking = False

        finally:
            if not finish_reason_received and not content_yielded:
                logger.warning("æµç»“æŸä½†æœªæ”¶åˆ°å®Œæˆä¿¡å·ã€‚")

    async def get_request_stream(
        self, messages: list, model_name: str
    ) -> AsyncGenerator[str, None]:
        """æ„å»ºè¯·æ±‚å¹¶ä» Gemini API æµå¼ä¼ è¾“å“åº”ï¼Œæ”¯æŒé€šè¿‡ File API ä¸Šä¼ å›¾ç‰‡ã€‚"""
        api_model = self.valves.api_model
        logger.info(
            f"ä¸º UI æ¨¡å‹ '{model_name}' å‡†å¤‡è¯·æ±‚ï¼Œä½¿ç”¨ API æ¨¡å‹ '{api_model}'ã€‚"
        )

        gemini_contents = []

        # ä½¿ç”¨ç‹¬ç«‹çš„ httpx Client è¿›è¡Œä¸Šä¼ æ“ä½œ
        async with httpx.AsyncClient(timeout=self.valves.timeout) as upload_client:
            for msg in messages:
                role = "user" if msg.get("role") == "user" else "model"
                content = msg.get("content")
                parts = []

                if isinstance(content, str):
                    parts.append({"text": content})
                elif isinstance(content, list):
                    for part in content:
                        part_type = part.get("type")
                        if part_type == "text":
                            parts.append({"text": part.get("text", "")})

                        elif part_type == "image_url":
                            image_url = part.get("image_url", {}).get("url", "")

                            mime_type = "image/jpeg"  # é»˜è®¤
                            image_bytes = None

                            # 1. å¤„ç† Data URI
                            if image_url.startswith("data:image"):
                                try:
                                    header, encoded_data = image_url.split(",", 1)
                                    mime_type = header.split(":", 1)[1].split(";", 1)[0]
                                    image_bytes = base64.b64decode(encoded_data)
                                except Exception as e:
                                    logger.error(f"è§£æ base64 å›¾ç‰‡æ•°æ®å¤±è´¥ï¼š{e}")
                                    await self.emit_status(
                                        "è­¦å‘Šï¼šè§£æå›¾ç‰‡æ•°æ®å¤±è´¥ï¼Œå·²è·³è¿‡å›¾ç‰‡ã€‚",
                                        done=False,
                                    )

                            # 2. å¤„ç†è¿œç¨‹ URL
                            elif image_url.startswith(
                                "http://"
                            ) or image_url.startswith("https://"):
                                if self.valves.file_api_key == "":
                                    await self.emit_status(
                                        "è­¦å‘Šï¼šæœªé…ç½®ä¸Šä¼  API Keyï¼Œæ— æ³•ä¸Šä¼ è¿œç¨‹å›¾ç‰‡ï¼Œå·²è·³è¿‡å›¾ç‰‡ã€‚",
                                        done=False,
                                    )
                                    continue
                                try:
                                    await self.emit_status(
                                        f"æ­£åœ¨ä¸‹è½½è¿œç¨‹å›¾ç‰‡...", done=False
                                    )
                                    resp = await upload_client.get(image_url)
                                    if resp.status_code == 200:
                                        image_bytes = resp.content
                                        import mimetypes

                                        guessed_type, _ = mimetypes.guess_type(
                                            image_url
                                        )
                                        if guessed_type:
                                            mime_type = guessed_type
                                    else:
                                        logger.error(
                                            f"ä¸‹è½½è¿œç¨‹å›¾ç‰‡å¤±è´¥ï¼š{resp.status_code}"
                                        )
                                except Exception as e:
                                    logger.error(f"ä¸‹è½½è¿œç¨‹å›¾ç‰‡å¼‚å¸¸ï¼š{e}")

                            # 3. æ‰§è¡Œä¸Šä¼ 
                            if image_bytes:
                                try:
                                    await self.emit_status(
                                        "æ­£åœ¨ä¸Šä¼ å›¾ç‰‡åˆ° Gemini...", done=False
                                    )
                                    file_uri = await self._upload_file(
                                        upload_client, mime_type, image_bytes
                                    )

                                    parts.append(
                                        {
                                            "file_data": {
                                                "mime_type": mime_type,
                                                "file_uri": file_uri,
                                            }
                                        }
                                    )
                                except Exception as e:
                                    error_msg = f"ä¸Šä¼ å›¾ç‰‡åˆ° Gemini å¤±è´¥ï¼š{e}"
                                    logger.error(error_msg)
                                    await self.emit_status(
                                        f"è­¦å‘Šï¼š{error_msg}", done=False
                                    )

                if parts:
                    gemini_contents.append({"role": role, "parts": parts})

        if gemini_contents and gemini_contents[-1]["role"] == "model":
            gemini_contents.append({"role": "user", "parts": [{"text": "Continue"}]})

        gemini_tools = [
            {"googleSearch": {}},
            {"code_execution": {}},
        ]

        data = {
            "contents": gemini_contents,
            "tools": gemini_tools,
            "generationConfig": {
                "temperature": self.uservalves.temperature,
                "topP": self.uservalves.top_p,
                "thinkingConfig": {
                    "includeThoughts": self.uservalves.include_thoughts,
                    "thinkingBudget": self.uservalves.thinking_budget,
                },
            },
        }

        url = f"/v1beta/models/{api_model}:streamGenerateContent?key={self.valves.api_key}&alt=sse"

        try:
            async with httpx.AsyncClient(
                base_url=self.valves.base_url,
                trust_env=True,
                timeout=self.valves.timeout,
            ) as client:
                await self.emit_status(
                    f"æ­£åœ¨å‘ Gemini æ¨¡å‹å‘é€è¯·æ±‚ï¼š{api_model}", done=False
                )
                async with client.stream("POST", url, json=data) as response:
                    if response.status_code != 200:
                        error_content = await response.aread()
                        error_message = f"ğŸš¨ Gemini API é”™è¯¯ï¼š{response.status_code} - {error_content.decode()}"
                        await self.emit_status(error_message, done=True)
                        yield error_message
                        return

                    async for content in self.process_stream(response):
                        yield content

        except httpx.ConnectError as e:
            error_msg = f"ğŸš¨ è¿æ¥é”™è¯¯ï¼šæ— æ³•è¿æ¥åˆ° {self.valves.base_url}ã€‚ {e}"
            logger.exception(error_msg)
            await self.emit_status(error_msg, done=True)
            yield error_msg
        except httpx.TimeoutException:
            error_msg = f"ğŸš¨ è¯·æ±‚è¶…æ—¶ï¼š{self.valves.timeout} ç§’è¶…æ—¶ã€‚"
            logger.error(error_msg)
            await self.emit_status(error_msg, done=True)
            yield error_msg
        except Exception as e:
            error_msg = f"ğŸš¨ å‘ç”Ÿæ„å¤–é”™è¯¯ï¼š{e}"
            logger.exception(error_msg)
            await self.emit_status(error_msg, done=True)
            yield error_msg

    async def pipe(
        self,
        body: dict,
        __user__: Optional[dict] = None,
        __event_emitter__: Optional[Callable[[dict], Awaitable[None]]] = None,
        __event_call__: Optional[Callable[[dict], Awaitable[dict]]] = None,
    ) -> AsyncGenerator[str, None]:
        """ç®¡é“çš„ä¸»å…¥å£ç‚¹ã€‚"""
        self.emitter = __event_emitter__
        self.uservalues = __user__.get("valves") if __user__ else self.UserValves()
        request_id = str(uuid.uuid4())
        logger.info(f"[{request_id}] ç®¡é“å¼€å§‹å¤„ç†æ–°è¯·æ±‚ã€‚")

        try:
            if not self.valves.api_key:
                error_msg = "âŒ é”™è¯¯ï¼šGemini API å¯†é’¥æœªè®¾ç½®ã€‚"
                yield error_msg
                await self.emit_status(error_msg, done=True)
                return

            messages = body.get("messages")
            model_id = body.get("model", self.valves.model_id)

            async for chunk in self.get_request_stream(messages, model_id):
                # å¤„ç†è¾“å‡ºæ¨¡å¼ï¼ˆåˆ†å—/å­—ç¬¦ï¼‰
                if self.uservalves.block_size > 1:
                    for chunk_part in self.split_html_tags(chunk):
                        if chunk_part.startswith("<") and chunk_part.endswith(">"):
                            yield chunk_part
                        else:
                            for i in range(
                                0, len(chunk_part), self.uservalves.block_size
                            ):
                                block = chunk_part[i : i + self.uservalves.block_size]
                                if block:
                                    yield block
                                    if self.uservalves.output_delay > 0:
                                        await asyncio.sleep(
                                            self.uservalves.output_delay
                                        )
                elif self.uservalves.block_size < 0:
                    # æŒ‰ç©ºæ ¼åˆ†å—
                    for chunk_part in self.split_html_tags(chunk):
                        if chunk_part.startswith("<") and chunk_part.endswith(">"):
                            yield chunk_part
                        else:
                            parts = re.split(r"(\s+)", chunk_part)
                            for part in parts:
                                if part:
                                    yield part
                                    if self.uservalves.output_delay > 0:
                                        await asyncio.sleep(
                                            self.uservalves.output_delay
                                        )
                else:
                    # é€å­—è¾“å‡º
                    skip = False
                    for char in chunk:
                        yield char
                        if char == "<":
                            skip = True
                        elif char == ">":
                            skip = False
                        if skip:
                            continue
                        if self.uservalves.output_delay > 0:
                            await asyncio.sleep(self.uservalves.output_delay)

            await self.emit_status("ç”Ÿæˆå®Œæˆã€‚", done=True)

        except Exception as e:
            error_msg = f"âŒ ç³»ç»Ÿé”™è¯¯ï¼š{e}"
            logger.exception(f"[{request_id}] {error_msg}")
            await self.emit_status(f"è‡´å‘½é”™è¯¯ï¼š{e}", done=True)
            yield error_msg
